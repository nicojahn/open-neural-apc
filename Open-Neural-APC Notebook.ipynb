{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2 implementation of Open-Neural-APC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extention to run neural-apc in google colab and retrieving all neccessary files\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/nicojahn/open-neural-apc.git\n",
    "    !rsync -a open-neural-apc/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install and update required packages\n",
    "python3 -m pip install --upgrade pip -q\n",
    "python3 -m pip install --upgrade -r requirements.txt -q\n",
    "\n",
    "# just for the video output/investigation (not necessary for training/testing)\n",
    "python3 -m pip install --upgrade -r optionals.txt -q\n",
    "\n",
    "# this is also optional, since it is only needed for opencv videos\n",
    "apt-get -qq update && apt-get -qq install -y libsm6 libxext6 libxrender1 libfontconfig1 libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import loadConfig, allow_growth\n",
    "from tqdm import tqdm\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "data_parameter, model_parameter, training_parameter = loadConfig()\n",
    "# Since I saved the data as \"uint8\" and the sensor is usually placed at a height of 2 meters\n",
    "#    the resolution should be just below 1cm\n",
    "#    but since the noise frames at the end of most sequences produce larger values, this might not be the case\n",
    "# The \"accuracy error niveau\" is the absolutely permissible difference so that a prediction \n",
    "#    on the label is still counted as correct (remember: it's a regression task)\n",
    "# The \"jump input frames\" parameter indicates which frames are used from the original sequence\n",
    "# The original sequences are at about 40 FPS. The model is trained with just 10 FPS\n",
    "# The \"pretrain\" parameter is not used so far but could be utilized with a pretraining of the input layer\n",
    "# The \"safe steps\" parameter is used to safe the model every \"safe steps\" epochs\n",
    "\n",
    "# switching between the gpus\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# disable annoying tf warnings (retracing etc.)\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# enable GPU memory growth\n",
    "allow_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable effcient data processing\n",
    "sequence_dtype = data_parameter[\"sequence dtype\"]\n",
    "labels_dtype = data_parameter[\"labels dtype\"]\n",
    "calculation_dtype = training_parameter[\"calculation dtype\"]\n",
    "calculation_epsilon = training_parameter[\"calculation epsilon\"]\n",
    "\n",
    "# enable single/half/double precision\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_floatx(calculation_dtype)\n",
    "K.set_epsilon(calculation_epsilon)\n",
    "\n",
    "# enable mixed precission\n",
    "if 'float16' in calculation_dtype:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    #loss_scale = tf.mixed_precision.experimental.DynamicLossScale(initial_loss_scale=(2 ** 15), increment_period=2000, multiplier=2.0)\n",
    "    policy = mixed_precision.Policy('mixed_float16')#, loss_scale=loss_scale)\n",
    "    mixed_precision.set_policy(policy)\n",
    "\n",
    "import numpy as np\n",
    "# scale saved input into a normed range \n",
    "input_scaling_factor = np.asarray(data_parameter[\"input scaling factor\"],dtype=calculation_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napc import NeuralAPC\n",
    "\n",
    "# First step into using multiple GPU's at once\n",
    "# Needs adaption of batch size and learning rate (for optimal performance)\n",
    "#strategy = tf.distribute.MirroredStrategy().scope()\n",
    "#strategy = tf.distribute.experimental.CentralStorageStrategy().scope()\n",
    "strategy = tf.init_scope() # Use again only 1 GPU\n",
    "with strategy:\n",
    "    napc = NeuralAPC(model_parameter,training_parameter)\n",
    "    napc.compile()\n",
    "    napc.save()\n",
    "\n",
    "# copy config into model folder\n",
    "import shutil\n",
    "config_path = shutil.copy2('config.json', napc.model_path)\n",
    "print(f'Config saved under {config_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "mode = \"training\"\n",
    "data_path = path.join(data_parameter['data directory'], f'{mode}.dat')\n",
    "lengths_path = path.join(data_parameter['data directory'], f'{mode}_meta.dat')\n",
    "\n",
    "# This one solves the problem for all of you, which just click 'Run all' and expect it to work\n",
    "# Since the training data is not uploaded 'on purpose', the code would usually break for most people\n",
    "# If the file does not exists, the code immediately jumps to the point, where it loads the 'predefined' model and evaluates it\n",
    "# Elsewise it trains the model and evalutes the newly trained\n",
    "data_exists = os.path.isfile(data_path)\n",
    "\n",
    "if data_exists:\n",
    "    print(\"Found the training data!\")\n",
    "    from data_loader import DataLoader\n",
    "    # due to the expertise of github.com/xor2k, I switched from CSV to memory-mapped files.\n",
    "    # This reduces the loading/mapping time by a lot.\n",
    "    # The sequence_list is a list containing all sequences for training (The sequences have the shape of Tx20x25)\n",
    "    # all sequences are differently long and are normalized in the range between 0. and 1., they have the dtype 'sequence_dtype'\n",
    "    # The labels_list is a list with all the labels for training in the same order as the sequence_list is.\n",
    "    # The shape of each label is 2 --> Therefore, the list could have the shape Nx2 as array. The labels have dtype 'labels_dtype'\n",
    "    data = DataLoader(model_parameter,training_parameter,data_path,lengths_path,sequence_dtype,labels_dtype)\n",
    "    # Similar to my bachelors thesis I used just about 1500 sequences (Not necessarily the same ones/ haven't checked it)\n",
    "    # Not necessary for other people or experiments\n",
    "    # sequence_list, labels_list = sequence_list[:training_parameter[\"restrict dataset size\"]], labels_list[:training_parameter[\"restrict dataset size\"]]\n",
    "else:\n",
    "    print(\"Oh nooo...Haven't found the training data. Therefore, no training possible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_generator import DataGenerator\n",
    "generator = None\n",
    "if data_exists:\n",
    "    # this is class which preprocesses the training data every epoch\n",
    "    # it creates the necessary labels/bounds and augments the data\n",
    "    generator = DataGenerator(data,input_scaling_factor,training_parameter,calculation_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from optional_features import customPlot\n",
    "# train\n",
    "if data_exists:\n",
    "    \n",
    "    callbacks = []\n",
    "    callbacks += [napc.IncreaseEpochCustom(napc)]\n",
    "    callbacks += [napc.SaveEveryNthEpochCustom(napc,training_parameter['safe steps'])]\n",
    "    # tensorboard callback\n",
    "    callbacks += [tf.keras.callbacks.TensorBoard(log_dir=napc.model_path+'/logs', histogram_freq=0, write_graph=True, \\\n",
    "                                                 write_images=False, update_freq='epoch', profile_batch=0, \\\n",
    "                                                 embeddings_freq=0, embeddings_metadata=None)]\n",
    "    # custom callback for creating the plots\n",
    "    '''\n",
    "    try: \n",
    "        callbacks += [customPlot(generator,napc,plot_freq=1000)]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    '''\n",
    "    \n",
    "    generator.on_epoch_end()\n",
    "    napc.model.fit(generator,epochs=training_parameter['epochs'],initial_epoch=napc.epoch,\\\n",
    "                   max_queue_size=generator.num_batches, workers=4, use_multiprocessing=False, callbacks=callbacks)\n",
    "    # the training took about 12-16 hours on a 2080TI while occupying less than 3GB VRAM and 80% GPU-Util.\n",
    "    # always depending on the LSTM implementation (CPU/GPU/CUDNN_TF1/CUDNN_TF2), the precision and data preparation\n",
    "    # got my fastest time per epoch training performance with 16bit(half->mixed) precision, CUDNN v1 implementation (without Dropout),\n",
    "    #   batchsize divisible by 16 (larger is not always better) and lstm layer width divisible by 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all of you which don't have the training data and just want to execute it\n",
    "if not data_exists:\n",
    "    data_parameter, model_parameter, training_parameter = loadConfig('models/config.json',verbose=False)\n",
    "    napc = NeuralAPC(model_parameter,training_parameter)\n",
    "    # Loading the included model (it has no subdirectory)\n",
    "    napc.loadModel(10000,'models/')\n",
    "    # The model_path of the model is not 'models/', but the previously created subdirectory\n",
    "    # You could now train it further/save it/ etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce videos on all validation sequences\n",
    "import os.path as path\n",
    "mode = \"validation\"\n",
    "data_path = path.join(data_parameter['data directory'], f'{mode}.dat')\n",
    "lengths_path = path.join(data_parameter['data directory'], f'{mode}_meta.dat')\n",
    "\n",
    "# de-/activate video creation\n",
    "create_vids = False\n",
    "\n",
    "# copy dict from training and modify the concatenation\n",
    "validation_parameter = training_parameter.copy()\n",
    "validation_parameter[\"minimum concatenation\"] = 1\n",
    "validation_parameter[\"maximum concatenation\"] = 1\n",
    "\n",
    "# read the validation data\n",
    "from data_loader import DataLoader\n",
    "data = DataLoader(model_parameter,validation_parameter,data_path,lengths_path,sequence_dtype,labels_dtype)\n",
    "\n",
    "# process them (i need the bounds in y for the accuracy and the videos)\n",
    "from data_generator import DataGenerator\n",
    "validation_generator = DataGenerator(data,input_scaling_factor,validation_parameter,calculation_dtype)\n",
    "# With training=False, no augmentation is applied to the input data\n",
    "# Therefore, results are the closest possible real-world setting\n",
    "validation_generator.on_epoch_end(training=False)\n",
    "\n",
    "from optional_features import createVideo\n",
    "accuracy = []\n",
    "for batch_idx in range(validation_generator.num_batches):\n",
    "    # get batch, predict and calculate accuracy\n",
    "    x,y = validation_generator[batch_idx]\n",
    "    predictions = napc.model.predict_on_batch(x)\n",
    "    accuracy += [K.eval(napc.accuracy(y,predictions))]\n",
    "    \n",
    "    # creates my videos\n",
    "    if create_vids:\n",
    "        # has to create the videos for every element\n",
    "        for sample_idx, prediction in enumerate(predictions):\n",
    "            output_dimensions = model_parameter['output dimensions']\n",
    "            \n",
    "            # mask/remove the padding if batched\n",
    "            binary_mask = (np.minimum(0,y[sample_idx,:,2*output_dimensions])+1).astype(bool)\n",
    "            input_sequence = tf.boolean_mask(x[sample_idx],binary_mask,axis=0)\n",
    "            pred = K.eval(tf.boolean_mask(prediction,binary_mask,axis=0))\n",
    "            lower_bound = tf.boolean_mask(y[sample_idx,:,0:output_dimensions],binary_mask,axis=0)\n",
    "            upper_bound = tf.boolean_mask(y[sample_idx,:,output_dimensions:2*output_dimensions],binary_mask,axis=0)\n",
    "\n",
    "            # if creating the video takes to long, you can adjust the default dpi=300 parameter\n",
    "            # napc.epoch and sample_idx are just used for the video name\n",
    "            # the other arguments are actually plotted in the video\n",
    "            createVideo(napc.epoch, sample_idx, input_sequence, pred, lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I'm not allowed to upload more sequences and I don't want to publish a perfect model\n",
    "# (therefore, I haven't tested this one) the accuracy is just an approximation of the true capabilities\n",
    "# The 'validation' data in this case is in fact a test set (last epoch was chosen without selection)\n",
    "# In practice someone would use k-Fold-Crossvalidation and would reason about the average performance\n",
    "\n",
    "# So let's have a look how well the model does...\n",
    "print(f'{mode} accuracy: {100*np.mean(accuracy)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'float16' in calculation_dtype:\n",
    "    # Check again if we've run our model with mixed precision\n",
    "    print('Compute dtype: %s' % policy.compute_dtype)\n",
    "    print('Variable dtype: %s' % policy.variable_dtype)\n",
    "    # Print the final loss scale\n",
    "    loss_scale = policy.loss_scale\n",
    "    print('Loss scale: %s' % loss_scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
