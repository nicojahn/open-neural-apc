{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Neural-APC as Tensorflow 2 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# install and update required packages\n",
    "!pip install --upgrade pip -q\n",
    "!pip install --upgrade -r requirements.txt -q\n",
    "\n",
    "# just for the video output/investigation (not necessary for training/testing)\n",
    "!pip install --upgrade -r optionals.txt -q\n",
    "# this is also optional, since it is needed for opencv\n",
    "!apt-get -qq update && apt-get -qq install -y libsm6 libxext6 libxrender1 libfontconfig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data parameter\": {\n",
      "    \"data directory\": \"./data/\",\n",
      "    \"input scaling factor\": 255,\n",
      "    \"labels dtype\": \"uint32\",\n",
      "    \"sequence dtype\": \"uint8\",\n",
      "    \"training label\": \"train.csv\",\n",
      "    \"validation label\": \"valid.csv\"\n",
      "  },\n",
      "  \"model parameter\": {\n",
      "    \"input dimensions\": [\n",
      "      20,\n",
      "      25\n",
      "    ],\n",
      "    \"lstm depth\": 5,\n",
      "    \"lstm width\": 50,\n",
      "    \"output dimensions\": 2\n",
      "  },\n",
      "  \"training parameter\": {\n",
      "    \"accuracy error niveau\": 0.5,\n",
      "    \"aux scale\": 3,\n",
      "    \"batch size\": 16,\n",
      "    \"calculation dtype\": \"float32\",\n",
      "    \"calculation epsilon\": 1e-07,\n",
      "    \"dropout rate\": 0.2,\n",
      "    \"epochs\": 10000,\n",
      "    \"jump input frames\": 4,\n",
      "    \"learning rate\": 0.001,\n",
      "    \"maximum concatenation\": 6,\n",
      "    \"minimum concatenation\": 4,\n",
      "    \"optimizer parameter\": [\n",
      "      0.9,\n",
      "      0.999,\n",
      "      1e-07\n",
      "    ],\n",
      "    \"pretrain\": false,\n",
      "    \"restrict dataset size\": 1500,\n",
      "    \"safe steps\": 5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from utils import loadConfig, allow_growth\n",
    "from tqdm import tqdm\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "data_parameter, model_parameter, training_parameter = loadConfig()\n",
    "# Since I saved the data as \"uint8\" and the sensor is usually placed at a height of 2 meters\n",
    "#    the resolution should be just below 1cm\n",
    "#    but since the noise frames at the end of most sequences produce larger values, this might not be the case\n",
    "# The \"accuracy error niveau\" is the absolutely permissible difference so that a prediction \n",
    "#    on the label is still counted as correct (remember: it's a regression task)\n",
    "# The \"jump input frames\" parameter indicates which frames are used from the original sequence\n",
    "# The original sequences are at about 40 FPS. The model is trained with just 10 FPS\n",
    "# The \"pretrain\" parameter is not used so far but could be utilized with a pretraining of the input layer\n",
    "# The \"safe steps\" parameter was used for the non-jupyter version to safe the model every 5 epochs\n",
    "\n",
    "# enable GPU memory growth \n",
    "allow_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable effcient data processing\n",
    "sequence_dtype = data_parameter[\"sequence dtype\"]\n",
    "labels_dtype = data_parameter[\"labels dtype\"]\n",
    "calculation_dtype = training_parameter[\"calculation dtype\"]\n",
    "calculation_epsilon = training_parameter[\"calculation epsilon\"]\n",
    "\n",
    "# enable single/half/double precision\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_floatx(calculation_dtype)\n",
    "K.set_epsilon(calculation_epsilon)\n",
    "\n",
    "import numpy as np\n",
    "# scale saved input into a normed range \n",
    "input_scaling_factor = np.asarray(data_parameter[\"input scaling factor\"],dtype=calculation_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config saved under ./models/2020-06-04_17:03:46.847015/config.json\n"
     ]
    }
   ],
   "source": [
    "from napc import NeuralAPC\n",
    "# This is the pure model. It's almost the same as in my bachelors thesis\n",
    "# The only difference is an additional loss (auxiliary loss) and a dropout layer after the first dense layer\n",
    "# Elsewise it's the same architecture, same optimizer, same 'main' loss\n",
    "napc = NeuralAPC(model_parameter,training_parameter)\n",
    "napc.compile()\n",
    "napc.save()\n",
    "\n",
    "# copy config into model folder\n",
    "import shutil\n",
    "config_path = shutil.copy2('config.json', napc.model_path)\n",
    "print(f'Config saved under {config_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "mode = \"training\"\n",
    "data = path.join(data_parameter['data directory'], f'{mode}.dat')\n",
    "data_lengths = path.join(data_parameter['data directory'], f'{mode}_meta.dat')\n",
    "\n",
    "# This one solves the problem for all of you, which just click 'Run all' and expect it to work\n",
    "# Since the training data is not uploaded 'on purpose', the code would usually break for most people\n",
    "# If the file does not exists, the code immediately jumps to the point, where it loads the 'predefined' model and evaluates it\n",
    "# Elsewise it trains the model and evalutes the newly trained\n",
    "data_exists = os.path.isfile(data)\n",
    "\n",
    "sequence_list = labels_list = None\n",
    "\n",
    "if data_exists:\n",
    "    from data_loader import readData\n",
    "    # due to the expertise of github.com/xor2k, I switched from CSV to memory-mapped files.\n",
    "    # This reduces the loading/mapping time by a lot.\n",
    "    sequence_list, labels_list = readData(model_parameter,training_parameter,data,data_lengths,sequence_dtype,labels_dtype)\n",
    "    # Similar to my bachelors thesis I used just about 1500 sequences (Not necessarily the same ones/ haven't checked it)\n",
    "    sequence_list, labels_list = sequence_list[:training_parameter[\"restrict dataset size\"]], labels_list[:training_parameter[\"restrict dataset size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_processing import Preprocess\n",
    "preprocessor = None\n",
    "if data_exists:\n",
    "    # this is class which preprocesses the data every epoch\n",
    "    # it creates the necessary labels/bounds and augments the data\n",
    "    preprocessor = Preprocess(sequence_list,labels_list,input_scaling_factor,training_parameter,calculation_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "if data_exists:\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    import time as t\n",
    "    train_start = t.time()\n",
    "\n",
    "    for epoch in tqdm(range(napc.epoch,training_parameter['epochs']),desc='Training progress'):\n",
    "        start = t.time()\n",
    "\n",
    "        X,Y = preprocessor.prepareEpoch()\n",
    "        prep_end = t.time()\n",
    "\n",
    "        for x,y in list(zip(X,Y)):\n",
    "            metrics = napc.model.train_on_batch(x,y,reset_metrics=False)\n",
    "\n",
    "        if epoch%100==0:\n",
    "            print(','.join( np.vstack([['epoch'],[epoch]]).T.flatten() )+','+\\\n",
    "                  ','.join( np.vstack([['t_total','t_prep','t_calc'],\\\n",
    "                            [round(t.time()-train_start,2),round(prep_end-start,2),\\\n",
    "                             round(t.time()-prep_end,2)]]).T.flatten() )+','+\\\n",
    "                  ','.join( np.vstack([napc.model.metrics_names,np.round(metrics,5)]).T.flatten() ))\n",
    "\n",
    "        napc.model.reset_metrics()\n",
    "        napc.epoch += 1\n",
    "\n",
    "        if epoch%1000==0:\n",
    "\n",
    "            sample = 0\n",
    "            x = x[sample:sample+1,:,:]\n",
    "            y = y[sample:sample+1,:,:]\n",
    "\n",
    "            prediction = napc.model.predict_on_batch(x)\n",
    "            error = napc.loss_function(y[:,:,:2],y[:,:,2:4],prediction)\n",
    "\n",
    "            # prepare plot\n",
    "            num_plots = 2\n",
    "            fig, ax = plt.subplots(1,num_plots,figsize=(14,3), dpi=80)\n",
    "            fig.suptitle('Predictions in/out')\n",
    "\n",
    "            for idx in range(num_plots):\n",
    "                ax[idx].plot(y[0,:,idx],label='max')\n",
    "                ax[idx].plot(y[0,:,idx+2],label='min')\n",
    "                ax[idx].plot(y[0,:,4],label='end')\n",
    "                ax[idx].plot(prediction[0,:,idx],label='prediction')\n",
    "                ax[idx].plot(error[0,:,idx],label='error')\n",
    "                ax[idx].legend()\n",
    "\n",
    "            plt.show(fig)\n",
    "    napc.save()\n",
    "    # the output of this cell are metrics every 10th epoch and a plot of the counting behaviour every 100th epoch\n",
    "    # the training took about 10 hours on a 2080TI while occupying less than 2GB VRAM and 80% GPU-Util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all of you which don't have the training data and just want to execute it\n",
    "if not data_exists:\n",
    "    # Loading the included model (it has no subdirectory)\n",
    "    napc.loadModel(10000,'models/')\n",
    "    # The model_path of the model is not 'models/', but the previously created subdirectory\n",
    "    # You could now train it further/save it/ etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading files: 17:03:50 2020-06-04\n",
      "Finished reading 15 sequences. Took 0.000000 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 534it [02:32,  3.51it/s]\n",
      "Video progress: 141it [00:33,  4.27it/s]\n",
      "Video progress: 146it [00:34,  4.24it/s]\n",
      "Video progress: 504it [02:10,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 131it [00:29,  4.49it/s]\n",
      "Video progress: 146it [00:34,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 147it [00:34,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 116it [00:24,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 177it [00:44,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 630it [03:32,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 151it [00:36,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 223it [00:48,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 137it [00:32,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c2c1f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Video progress: 293it [01:14,  3.91it/s]\n",
      "Video progress: 146it [00:34,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# produce videos on all validation sequences\n",
    "import os.path as path\n",
    "mode = \"validation\"\n",
    "data = path.join(data_parameter['data directory'], f'{mode}.dat')\n",
    "data_lengths = path.join(data_parameter['data directory'], f'{mode}_meta.dat')\n",
    "\n",
    "# copy dict from training and modify the concatenation and batch size\n",
    "validation_parameter = training_parameter.copy()\n",
    "validation_parameter[\"minimum concatenation\"] = 1\n",
    "validation_parameter[\"maximum concatenation\"] = 1\n",
    "validation_parameter[\"batch size\"]=1\n",
    "\n",
    "# read the validation data\n",
    "from data_loader import readData\n",
    "sequence_list, labels_list = readData(model_parameter,validation_parameter,data,data_lengths,sequence_dtype,labels_dtype)\n",
    "\n",
    "# process them (i need the bounds in y for the accuracy and the videos)\n",
    "from data_processing import Preprocess\n",
    "preprocessor = Preprocess(sequence_list,labels_list,input_scaling_factor,validation_parameter,calculation_dtype)\n",
    "X,Y = preprocessor.prepareEpoch(training=False)\n",
    "\n",
    "# create my videos\n",
    "from optional_features import createVideo\n",
    "accuracy = []\n",
    "for idx,x,y in list(zip(range(len(X)),X,Y)):\n",
    "    prediction = napc.model.predict_on_batch(x)\n",
    "    createVideo(napc.epoch,idx,x,K.eval(prediction),y[:,:,0:2],y[:,:,2:4])\n",
    "    accuracy += [K.eval(napc.accuracy(y,prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 96.66666388511658 %\n"
     ]
    }
   ],
   "source": [
    "# Since I'm not allowed to upload more sequences and I don't want to publish a perfect model\n",
    "# (therefore, I haven't tested this one) the accuracy is just an approximation of the true capabilities\n",
    "# The 'validation' data in this case is in fact a test set (last epoch was chosen without selection)\n",
    "# In practice someone would use k-Fold-Crossvalidation and would reason about the average performance\n",
    "\n",
    "# So let's have a look how well the model does...\n",
    "print(f'{mode} accuracy: {100*np.mean(accuracy)} %')\n",
    "# Not bad, it's even above 96%!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
